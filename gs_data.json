{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "6Cqm0pYAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Bin Zhang", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=6Cqm0pYAAAAJ&citpid=6", "affiliation": "Institute of Automation,Chinese Academy of Sciences", "organization": 2751420617708739826, "interests": ["AI Agent", "Multi-agent System", "Reinforcement Learning"], "email_domain": "@ia.ac.cn", "homepage": "https://binz98.github.io/", "citedby": 885, "publications": {"6Cqm0pYAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:ldfaerwXgEUC", "num_citations": 240, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=215173853357937829,7916725756616343845", "cites_id": ["215173853357937829", "7916725756616343845"]}, "6Cqm0pYAAAAJ:O3NaXMp0MMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Industry Systems", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:O3NaXMp0MMsC", "num_citations": 81, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12804145351990415605", "cites_id": ["12804145351990415605"]}, "6Cqm0pYAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Benchmarking the text-to-sql capability of large language models: A comprehensive evaluation", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:aqlVkmm33-oC", "num_citations": 81, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6936360426016072441", "cites_id": ["6936360426016072441"]}, "6Cqm0pYAAAAJ:35N4QoGY0k4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:35N4QoGY0k4C", "num_citations": 78, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=563717665474558821,2964615776370782663", "cites_id": ["563717665474558821", "2964615776370782663"]}, "6Cqm0pYAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Controlling large language model-based agents for large-scale decision-making: An actor-critic approach", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:4DMP91E08xMC", "num_citations": 54, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10440225051696517544", "cites_id": ["10440225051696517544"]}, "6Cqm0pYAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HAVEN: hierarchical cooperative multi-agent reinforcement learning with dual coordination mechanism", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:Tyk-4Ss8FVUC", "num_citations": 52, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5123918610354998382", "cites_id": ["5123918610354998382"]}, "6Cqm0pYAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Consensus learning for cooperative multi-agent reinforcement learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:IjCSPb-OGe4C", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14568163160915471279", "cites_id": ["14568163160915471279"]}, "6Cqm0pYAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PTDE: Personalized training with distilled execution for multi-agent reinforcement learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:Y0pCki6q_DkC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14024658041360231111", "cites_id": ["14024658041360231111"]}, "6Cqm0pYAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sequential Asynchronous Action Coordination in Multi-Agent Systems: A Stackelberg Decision Transformer Approach", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:BqipwSGYUEgC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6919078722480087898,7467691655612346564", "cites_id": ["6919078722480087898", "7467691655612346564"]}, "6Cqm0pYAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "From explicit communication to tacit cooperation: A novel paradigm for cooperative marl", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:hqOjcs7Dif8C", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12114270828108588849", "cites_id": ["12114270828108588849"]}, "6Cqm0pYAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mingling foresight with imagination: Model-based cooperative multi-agent reinforcement learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:LkGwnXOMwfcC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14537125056372349100", "cites_id": ["14537125056372349100"]}, "6Cqm0pYAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Inducing Stackelberg Equilibrium through Spatio-Temporal Sequential Decision-Making in Multi-Agent Reinforcement Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:8k81kl-MbHgC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1223657171119200790", "cites_id": ["1223657171119200790"]}, "6Cqm0pYAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive parameter sharing for multi-agent reinforcement learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:KlAtU1dfN6UC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13938572418029472011", "cites_id": ["13938572418029472011"]}, "6Cqm0pYAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Cooperative multi-agent reinforcement learning with hypergraph convolution", "pub_year": "2022"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:eQOLeE2rZwMC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13766256080002157998,11318527247894998203", "cites_id": ["13766256080002157998", "11318527247894998203"]}, "6Cqm0pYAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SIDE: State Inference for Partially Observable Cooperative Multi-Agent Reinforcement Learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:qjMakFHDy7sC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18439197367794191145", "cites_id": ["18439197367794191145"]}, "6Cqm0pYAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient Policy Generation in Multi-agent Systems via Hypergraph Neural Network", "pub_year": "2022"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:_FxGoFyzp5QC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10713222487937556913,402575267491201004", "cites_id": ["10713222487937556913", "402575267491201004"]}, "6Cqm0pYAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PDiT: Interleaving Perception and Decision-making Transformers for Deep Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:Zph67rFs4hoC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14032587176608926530", "cites_id": ["14032587176608926530"]}, "6Cqm0pYAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual self-awareness value decomposition framework without individual global max for cooperative MARL", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:MXK_kJrjxJIC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3253153394907270703,6190100019693295089", "cites_id": ["3253153394907270703", "6190100019693295089"]}, "6Cqm0pYAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning to coordinate via multiple graph neural networks", "pub_year": "2021"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:u5HHmVD_uO8C", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5344975883652967356", "cites_id": ["5344975883652967356"]}, "6Cqm0pYAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Verco: Learning Coordinated Verbal Communication for Multi-agent Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:TFP_iSt0sucC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1856635511869269307", "cites_id": ["1856635511869269307"]}, "6Cqm0pYAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Beyond Local Views: Global State Inference with Diffusion Models for Cooperative Multi-Agent Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:hMod-77fHWUC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15294047583243221830", "cites_id": ["15294047583243221830"]}, "6Cqm0pYAAAAJ:vV6vV6tmYwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient Communication in Multi-Agent Reinforcement Learning with Implicit Consensus Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:vV6vV6tmYwMC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2793801726930819796", "cites_id": ["2793801726930819796"]}, "6Cqm0pYAAAAJ:dfsIfKJdRG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Query-dependent Prompt Optimization via Multi-Loop Offline Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:dfsIfKJdRG4C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9754474428486698970,14622138332636125401", "cites_id": ["9754474428486698970", "14622138332636125401"]}, "6Cqm0pYAAAAJ:pqnbT2bcN3wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Graph of Verification: Structured Verification of LLM Reasoning with Directed Acyclic Graphs", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:pqnbT2bcN3wC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6632887802951315674", "cites_id": ["6632887802951315674"]}, "6Cqm0pYAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sea: A spatially explicit architecture for multi-agent reinforcement learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:Se3iqnhoufwC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16931031850846861013", "cites_id": ["16931031850846861013"]}, "6Cqm0pYAAAAJ:4OULZ7Gr8RgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:4OULZ7Gr8RgC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12765654241795180236", "cites_id": ["12765654241795180236"]}, "6Cqm0pYAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-agent hyper-attention policy optimization", "pub_year": "2022"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:ufrVoPGSRksC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17665032693002444889", "cites_id": ["17665032693002444889"]}, "6Cqm0pYAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Constructing Informative Subtask Representations for Multi-Agent Coordination", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:_kc_bZDykSQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4988001006190092953", "cites_id": ["4988001006190092953"]}, "6Cqm0pYAAAAJ:cFHS6HbyZ2cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Peak-Return Greedy Slicing: Subtrajectory Selection for Transformer-based Offline RL", "pub_year": "2026"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:cFHS6HbyZ2cC", "num_citations": 0}, "6Cqm0pYAAAAJ:u_35RYKgDlwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subgoal Graph-Augmented Planning for LLM-Guided Open-World Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:u_35RYKgDlwC", "num_citations": 0}, "6Cqm0pYAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reidentify: Context-Aware Identity Generation for Contextual Multi-Agent Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:ZHo1McVdvXMC", "num_citations": 0}, "6Cqm0pYAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Branching Policy Generalization through Self-Supervised Adversarial Instance Augmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:zA6iFVUQeVQC", "num_citations": 0}, "6Cqm0pYAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unveiling Decision Intention for Cooperative Multi-Agent Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:2P1L_qKh6hAC", "num_citations": 0}, "6Cqm0pYAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Better Branching Policies: Leveraging the Sequential Nature of Branch-and-Bound Tree", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:rO6llkc54NcC", "num_citations": 0}, "6Cqm0pYAAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GATE: Guided Contrastive State Space for Multi-agent Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:SeFeTyx0c_EC", "num_citations": 0}, "6Cqm0pYAAAAJ:HoB7MX3m0LUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Decentralized Extension for Centralized Multi-Agent Reinforcement Learning via Online Distillation", "pub_year": "2025"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:HoB7MX3m0LUC", "num_citations": 0}, "6Cqm0pYAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SGCD: Subgroup Contribution Decomposition for Multi-Agent Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "6Cqm0pYAAAAJ:GnPB-g6toBAC", "num_citations": 0}}, "citedby5y": 883, "hindex": 15, "hindex5y": 15, "i10index": 20, "i10index5y": 20, "cites_per_year": {"2022": 11, "2023": 76, "2024": 277, "2025": 460, "2026": 57}, "updated": "2026-02-28 08:25:08.869045"}